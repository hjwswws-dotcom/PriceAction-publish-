"""
PriceAction ä¸»å…¥å£æ¨¡å— - å¼‚æ­¥æ¶æ„ç‰ˆæœ¬
æ”¯æŒå¹¶å‘æ•°æ®è·å–å’Œå¤šå‘¨æœŸå…±æŒ¯åˆ†æ
"""

import sys
import time
import threading
import sqlite3
import asyncio
import json
from pathlib import Path
from typing import Dict, List, Optional, Any

# æ·»åŠ srcç›®å½•åˆ°è·¯å¾„
src_path = Path(__file__).parent.parent
if str(src_path) not in sys.path:
    sys.path.insert(0, str(src_path))

# å¹¶å‘ä¿æŠ¤é” - é˜²æ­¢åˆ†æå¾ªç¯é‡å æ‰§è¡Œ
_analysis_lock = threading.Lock()

# æ–°é—»æŠ“å–æ¨¡å—å¯¼å…¥
from src.data.news.cryptocompare_scraper import CryptoCompareScraper
from src.data.news.refiner import Refiner
from src.data.news.analyzer import NewsAnalyzer


def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“å’Œè¡¨ç»“æ„"""
    db_path = "./data.db"
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    # ğŸ”§ å¼ºåˆ¶é‡ç½®ï¼šæ£€æŸ¥å¹¶åˆ é™¤æ‰€æœ‰æ—§è¡¨ï¼Œç¡®ä¿ schema ç»å¯¹æ­£ç¡®
    tables_to_reset = [
        "states",
        "news_items",
        "refined_docs",
        "news_signals",
        "trading_signals",
        "trades",
    ]
    for table in tables_to_reset:
        cursor.execute(f"DROP TABLE IF EXISTS {table}")
        print(f"[DB] å·²åˆ é™¤æ—§è¡¨: {table}")

    # ğŸ”§ å¼ºåˆ¶é‡å»ºï¼šåˆ›å»ºå®Œæ•´çš„ states è¡¨ç»“æ„
    cursor.execute("""
        CREATE TABLE states (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            symbol TEXT,
            timeframe TEXT,
            timestamp INTEGER,
            marketCycle TEXT,
            marketStructure TEXT,
            signalConfidence INTEGER,
            activeNarrative TEXT,
            alternativeNarrative TEXT,
            actionPlan TEXT,
            volumeProfile TEXT,
            keyLevels TEXT,
            analysis_text TEXT,
            raw_response TEXT,
            consensus_score REAL,
            consensus_direction TEXT,
            last_updated INTEGER
        )
    """)

    # åˆ›å»ºç´¢å¼•
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_states_symbol ON states(symbol)")
    cursor.execute("CREATE INDEX IF NOT EXISTS idx_states_timeframe ON states(timeframe)")

    # ğŸ”§ å¼ºåˆ¶é‡å»ºï¼šåˆ›å»ºå®Œæ•´çš„ news_items è¡¨
    cursor.execute("""
        CREATE TABLE news_items (
            id TEXT PRIMARY KEY,
            source TEXT,
            source_item_id TEXT,
            title TEXT,
            url TEXT,
            published_time_utc INTEGER,
            ingest_time_utc INTEGER,
            content TEXT,
            language TEXT,
            votes_positive INTEGER DEFAULT 0,
            votes_negative INTEGER DEFAULT 0,
            votes_installed INTEGER DEFAULT 0,
            domain TEXT,
            kind TEXT,
            status TEXT DEFAULT 'NEW',
            created_at INTEGER,
            updated_at INTEGER
        )
    """)

    # ğŸ”§ å¼ºåˆ¶é‡å»ºï¼šåˆ›å»ºå®Œæ•´çš„ refined_docs è¡¨
    cursor.execute("""
        CREATE TABLE refined_docs (
            id TEXT PRIMARY KEY,
            news_id TEXT,
            url TEXT,
            title TEXT,
            markdown_content TEXT,
            summary TEXT,
            key_entities TEXT,
            quotes TEXT,
            status TEXT,
            error_message TEXT,
            created_at INTEGER,
            updated_at INTEGER
        )
    """)

    # ğŸ”§ å¼ºåˆ¶é‡å»ºï¼šåˆ›å»ºå®Œæ•´çš„ news_signals è¡¨ï¼ˆåŒ…å« severity å­—æ®µï¼‰
    cursor.execute("""
        CREATE TABLE news_signals (
            signal_id TEXT PRIMARY KEY,
            event_type TEXT,
            one_line_thesis TEXT,
            assets TEXT,
            direction TEXT,
            confidence INTEGER,
            timeframe TEXT,
            impact_volatility INTEGER,
            tail_risk INTEGER,
            news_ids TEXT,
            evidence_urls TEXT,
            is_active INTEGER DEFAULT 1,
            created_time_utc INTEGER,
            expires_time_utc INTEGER,
            severity TEXT DEFAULT 'INFO'
        )
    """)

    # ğŸ”§ å¼ºåˆ¶é‡å»ºï¼šåˆ›å»º trading_signals è¡¨
    cursor.execute("""
        CREATE TABLE trading_signals (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            symbol TEXT,
            timeframe TEXT,
            timestamp INTEGER,
            signal_type TEXT,
            direction TEXT,
            entry_price REAL,
            stop_loss REAL,
            take_profit REAL,
            confidence INTEGER,
            pattern_name TEXT,
            signal_checks TEXT,
            status TEXT DEFAULT 'ACTIVE',
            created_at INTEGER,
            updated_at INTEGER
        )
    """)

    # ğŸ”§ å¼ºåˆ¶é‡å»ºï¼šåˆ›å»º trades è¡¨
    cursor.execute("""
        CREATE TABLE trades (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            symbol TEXT,
            timeframe TEXT,
            direction TEXT,
            status TEXT DEFAULT 'ANALYZED',
            entry_price REAL,
            stop_loss REAL,
            take_profit_1 REAL,
            take_profit_2 REAL,
            win_probability REAL,
            position_size_actual REAL,
            position_size_suggested REAL,
            risk_amount_percent REAL,
            risk_reward_expected REAL,
            volatility_atr REAL,
            volatility_atr_15m REAL,
            volatility_atr_1h REAL,
            volatility_atr_1d REAL,
            sharpe_ratio_estimate REAL,
            kelly_fraction REAL,
            kelly_fraction_adjusted REAL,
            max_drawdown_estimate REAL,
            r_multiple_plan TEXT,
            stop_distance_percent REAL,
            ai_risk_analysis TEXT,
            ai_recommendation TEXT,
            risk_level TEXT,
            analysis_timestamp INTEGER,
            user_notes TEXT,
            outcome_feedback TEXT,
            created_at INTEGER,
            updated_at INTEGER
        )
    """)

    conn.commit()
    print("[DB] æ•°æ®åº“å·²å¼ºåˆ¶é‡ç½®ï¼Œæ‰€æœ‰è¡¨å·²é‡å»º")

    conn.close()


def _save_consolidated_state(
    symbol: str,
    timeframe_states: Dict[str, Dict],
    consensus: Dict,
    db,
    raw_response: str = "",
    analysis_text: str = "",
):
    """ä¿å­˜ç»Ÿä¸€çš„åˆ†æçŠ¶æ€åˆ°æ•°æ®åº“ï¼ˆåŒ…å«å…±æŒ¯ä¿¡æ¯ï¼‰"""
    import time as time_module

    for tf, state in timeframe_states.items():
        db_state = {
            "symbol": symbol,
            "timeframe": tf,
            "marketCycle": state.get("marketCycle", "TRADING_RANGE"),
            "activeNarrative": json.dumps(state.get("activeNarrative", {}), ensure_ascii=False),
            "alternativeNarrative": json.dumps(
                state.get("alternativeNarrative", {}), ensure_ascii=False
            ),
            "analysis_text": analysis_text,  # ğŸ”§ ç§»é™¤ tf == "15m" çš„åˆ¤æ–­ï¼Œå…¨å‘¨æœŸä¿å­˜
            "actionPlan": json.dumps(state.get("actionPlan", {}), ensure_ascii=False),
            "consensus_score": consensus.get("confidence", 0.0),
            "consensus_direction": consensus.get("direction", "NEUTRAL"),
            "last_updated": int(time_module.time() * 1000),  # ä¿å­˜ UTC æ—¶é—´æˆ³ï¼Œå‰ç«¯è´Ÿè´£æ—¶åŒºè½¬æ¢
            "raw_response": raw_response,  # ğŸ”§ å…¨å‘¨æœŸä¿å­˜åŸå§‹å“åº”ï¼Œä¸åšè¿‡æ»¤
        }

        db._ensure_connection()
        cursor = db._conn.cursor()
        cursor.execute(
            """
            INSERT OR REPLACE INTO states
            (symbol, timeframe, marketCycle, activeNarrative, alternativeNarrative, 
             analysis_text, actionPlan, consensus_score, consensus_direction, last_updated, raw_response)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """,
            (
                db_state["symbol"],
                db_state["timeframe"],
                db_state["marketCycle"],
                db_state["activeNarrative"],
                db_state["alternativeNarrative"],
                db_state["analysis_text"],
                db_state["actionPlan"],
                db_state["consensus_score"],
                db_state["consensus_direction"],
                db_state["last_updated"],
                db_state["raw_response"],
            ),
        )
        db._conn.commit()


def _analyze_single_timeframe(symbol, tf, klines, db, llm):
    """å•å‘¨æœŸé™çº§åˆ†æ"""
    try:
        current_state = db.get_state(symbol, tf)
        result = llm.analyze(symbol, klines, current_state)

        if result and result.get("success"):
            _save_timeframe_state(symbol, tf, result, db, result)
            current_price = klines[-1].get("close", 0) if klines else 0
            print(f"  [OK] {symbol} {tf} @ {current_price:.2f} (é™çº§)")
        else:
            print(f"  [ERROR] {symbol} {tf}: å•å‘¨æœŸåˆ†æä¹Ÿå¤±è´¥")
    except Exception as e:
        print(f"  [ERROR] {symbol} {tf}: {e}")


def _save_timeframe_state(symbol, tf, result, db, full_result):
    """ä¿å­˜å•å‘¨æœŸåˆ†æç»“æœåˆ°æ•°æ®åº“ï¼ˆé™çº§æ—¶ä½¿ç”¨ï¼‰"""
    import json
    import time

    state = {
        "symbol": symbol,
        "timeframe": tf,
        "marketCycle": result.get("marketCycle", "TRADING_RANGE"),
        "activeNarrative": json.dumps(result.get("activeNarrative", {}), ensure_ascii=False),
        "alternativeNarrative": json.dumps(
            result.get("alternativeNarrative", {}), ensure_ascii=False
        ),
        "analysis_text": full_result.get("analysis_text", ""),
        "actionPlan": json.dumps(result.get("actionPlan", {}), ensure_ascii=False),
        "consensus_score": 0.0,
        "consensus_direction": "NEUTRAL",
        "last_updated": int(time.time() * 1000),
        "raw_response": full_result.get("raw_response", ""),
    }

    db._ensure_connection()
    cursor = db._conn.cursor()
    cursor.execute(
        """
        INSERT OR REPLACE INTO states
        (symbol, timeframe, marketCycle, activeNarrative, alternativeNarrative, 
         analysis_text, actionPlan, consensus_score, consensus_direction, last_updated, raw_response)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    """,
        (
            state["symbol"],
            state["timeframe"],
            state["marketCycle"],
            state["activeNarrative"],
            state["alternativeNarrative"],
            state["analysis_text"],
            state["actionPlan"],
            state["consensus_score"],
            state["consensus_direction"],
            state["last_updated"],
            state["raw_response"],
        ),
    )
    db._conn.commit()


async def process_symbol_async(
    symbol: str, timeframes: List[str], fetcher, llm, db, consensus_calc
) -> bool:
    """
    å¼‚æ­¥å¤„ç†å•ä¸ªäº¤æ˜“å¯¹çš„å¤šå‘¨æœŸåˆ†æ

    Args:
        symbol: äº¤æ˜“å¯¹ç¬¦å·
        timeframes: æ—¶é—´æ¡†æ¶åˆ—è¡¨
        fetcher: å¼‚æ­¥æ•°æ®è·å–å™¨
        llm: LLM Provider
        db: æ•°æ®åº“ç®¡ç†å™¨
        consensus_calc: å…±æŒ¯è®¡ç®—å™¨

    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    print(f"æ­£åœ¨åˆ†æ {symbol}...")

    try:
        # 1. å¹¶å‘è·å–æ‰€æœ‰å‘¨æœŸçš„Kçº¿æ•°æ®
        print(f"  å¹¶å‘è·å– {len(timeframes)} ä¸ªå‘¨æœŸæ•°æ®...")
        timeframe_data = await fetcher.fetch_all_timeframes(symbol, timeframes, limit=50)

        valid_timeframes = {tf: data for tf, data in timeframe_data.items() if data}
        if not valid_timeframes:
            print(f"  [ERROR] {symbol}: æ— æ³•è·å–ä»»ä½•Kçº¿æ•°æ®")
            return False

        for tf, data in valid_timeframes.items():
            print(f"  âœ“ {tf}: {len(data)} æ ¹Kçº¿")

        # 2. è·å–å„å‘¨æœŸå½“å‰çŠ¶æ€
        current_states = {}
        for tf in valid_timeframes.keys():
            current_states[tf] = db.get_state(symbol, tf)

        # è·å–æ–°é—»ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        news_context = None
        recent_signals = db.get_latest_news_signals(limit=5)
        if recent_signals:
            news_context = {
                "items": recent_signals,
                "risk_summary": {"level": "NORMAL" if not recent_signals else "CAUTION"},
            }

        # 3. è°ƒç”¨å¤šå‘¨æœŸAIåˆ†æï¼ˆä¼ å…¥RAGå’Œæ–°é—»ï¼‰
        print(f"  è°ƒç”¨å¤šå‘¨æœŸAIåˆ†æ...")
        result = llm.analyze_multi_timeframe(
            symbol,
            valid_timeframes,
            current_states,
            rag_context="",  # æš‚æ—¶ä¸ºç©ºï¼Œåç»­å¯é›†æˆRAG
            news_context=news_context,
        )

        if not result.get("success"):
            print(f"  [ERROR] {symbol}: AIåˆ†æå¤±è´¥ - {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            # é™çº§ï¼šå°è¯•å•å‘¨æœŸåˆ†æ
            for tf, klines in valid_timeframes.items():
                _analyze_single_timeframe(symbol, tf, klines, db, llm)
            return False

        # 4. è§£æå¤šå‘¨æœŸç»“æœ
        from src.core.response_parser import ResponseParser

        parse_result = ResponseParser().parse_multi_timeframe(result.get("raw_response", ""))

        if not parse_result.get("success"):
            print(f"  [WARNING] {symbol}: å¤šå‘¨æœŸè§£æå¤±è´¥ï¼Œå°è¯•é™çº§")
            for tf, klines in valid_timeframes.items():
                _analyze_single_timeframe(symbol, tf, klines, db, llm)
            return False

        # 5. æå–å„å‘¨æœŸçŠ¶æ€
        timeframe_states = parse_result.get("timeframe_states", {})

        # 6. è®¡ç®—å…±æŒ¯åˆ†æ•°ï¼ˆå…³é”®æ”¹è¿›ï¼ï¼‰
        states_for_consensus = []
        for tf, state in timeframe_states.items():
            state_copy = state.copy()
            state_copy["symbol"] = symbol
            state_copy["timeframe"] = tf
            states_for_consensus.append(state_copy)

        consensus = consensus_calc.calculate_consensus(states_for_consensus)
        print(f"  å…±æŒ¯åˆ†æ: {consensus['direction']} (ç½®ä¿¡åº¦: {consensus['confidence']:.0%})")

        # 7. ä¸€æ¬¡æ€§ä¿å­˜æ‰€æœ‰å‘¨æœŸçš„çŠ¶æ€å’Œå…±æŒ¯ä¿¡æ¯
        _save_consolidated_state(
            symbol,
            timeframe_states,
            consensus,
            db,
            raw_response=result.get("raw_response", ""),
            analysis_text=parse_result.get("analysis_text", ""),
        )

        # 8. è¾“å‡ºç»“æœæ‘˜è¦
        for tf in valid_timeframes.keys():
            if tf in timeframe_states:
                current_price = valid_timeframes[tf][-1].get("close", 0)
                print(f"  [OK] {symbol} {tf} @ {current_price:.2f}")

        print(f"  {symbol} å¤šå‘¨æœŸåˆ†æå®Œæˆ (å…±æŒ¯: {consensus['recommendation']})")
        return True

    except Exception as e:
        print(f"  [ERROR] {symbol}: {e}")
        import traceback

        traceback.print_exc()
        return False


async def run_analysis_cycle_async(settings):
    """
    æ‰§è¡Œå¼‚æ­¥åˆ†æå¾ªç¯

    Args:
        settings: é…ç½®å¯¹è±¡
    """
    # åˆå§‹åŒ–æ•°æ®åº“
    init_database()

    from database import DatabaseManager
    from src.data_provider.async_ccxt_fetcher import AsyncCCXTFetcher
    from src.llm.siliconflow_provider import SiliconFlowProvider
    from src.core.consensus_calculator import ConsensusCalculator

    db = DatabaseManager("./data.db")
    db._ensure_connection()

    # è·å–é…ç½®
    symbols = settings.symbols
    timeframes = settings.timeframes
    api_key = settings.api_key

    # åˆå§‹åŒ–ç»„ä»¶
    proxy = settings.proxy
    exchange_id = settings.exchange_id
    exchange_options = (
        json.loads(settings.exchange_options)
        if settings.exchange_options
        else {"defaultType": "swap"}
    )

    # åˆå§‹åŒ–å…±æŒ¯è®¡ç®—å™¨ï¼ˆæƒé‡ï¼šæ—¥çº¿æœ€é«˜ï¼Œå°æ—¶æ¬¡ä¹‹ï¼Œ15åˆ†é’Ÿæœ€ä½ï¼‰
    consensus_weights = {"15m": 0.3, "1h": 0.6, "1d": 1.0}
    consensus_calc = ConsensusCalculator(consensus_weights)

    # åˆå§‹åŒ–LLM
    llm = SiliconFlowProvider(api_key=api_key)

    print(f"åˆ†æ {len(symbols)} ä¸ªäº¤æ˜“å¯¹...")

    # ä½¿ç”¨å¼‚æ­¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç®¡ç†fetcherç”Ÿå‘½å‘¨æœŸ
    async with AsyncCCXTFetcher(
        exchange_id=exchange_id, proxy=proxy, options=exchange_options
    ) as fetcher:
        # é¡ºåºå¤„ç†æ¯ä¸ªå¸ç§ï¼ˆé¿å…APIé™æµï¼‰ï¼Œä½†æ¯ä¸ªå¸ç§å†…éƒ¨å¹¶å‘è·å–å¤šå‘¨æœŸæ•°æ®
        for symbol in symbols:
            await process_symbol_async(
                symbol=symbol,
                timeframes=timeframes,
                fetcher=fetcher,
                llm=llm,
                db=db,
                consensus_calc=consensus_calc,
            )

    db.close()
    print("åˆ†æå®Œæˆ")


def run_analysis_cycle(settings):
    """åŒæ­¥åŒ…è£…å™¨ - è¿å¼‚æ­¥åˆ†æå¾ªç¯"""
    asyncio.run(run_analysis_cycle_async(settings))


def run_news_pipeline(db, proxy):
    """æ‰§è¡Œæ–°é—»æŠ“å–å’Œå¤„ç†æµæ°´çº¿"""
    try:
        print("[News] å¼€å§‹æ–°é—»æŠ“å–...")

        # 1. æŠ“å–æ–°é—»
        scraper = CryptoCompareScraper(db, proxy=proxy)
        news_items = scraper.fetch(limit=10)

        for item in news_items:
            db.save_news_item(item)

        print(f"[News] æŠ“å–äº† {len(news_items)} æ¡æ–°é—»")

        # 2. æçº¯å†…å®¹
        refiner = Refiner(db)
        refined_count = 0

        recent_news = db.get_recent_news_items(limit=10)
        for news_item in recent_news:
            if news_item.get("status") == "NEW":
                refined = refiner.refine(news_item["id"], news_item["url"])
                if refined:
                    db.save_refined_doc(refined)
                    refined_count += 1

        print(f"[News] æçº¯äº† {refined_count} æ¡æ–‡æ¡£")

        # 3. åˆ†æäº‹ä»¶
        analyzer = NewsAnalyzer(db)
        signal_count = 0

        for doc in recent_news:
            if doc.get("status") == "COMPLETED":
                signal = analyzer.extract_signals(doc)
                if signal:
                    db.save_news_signal(signal)
                    signal_count += 1

        print(f"[News] æå–äº† {signal_count} ä¸ªä¿¡å·")

        # 4. æ¸…ç†è¿‡æœŸä¿¡å·
        db.deactivate_expired_signals()

        print("[News] æ–°é—»æµæ°´çº¿å®Œæˆ")

    except Exception as e:
        print(f"[News Error] æ–°é—»æµæ°´çº¿å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()


def run_backend():
    """å¯åŠ¨åç«¯åˆ†ææœåŠ¡"""
    # âœ… æ­¥éª¤ 0: æœ€å…ˆåˆå§‹åŒ–æ•°æ®åº“ï¼ˆå»ºè¡¨/é‡ç½®è¡¨ç»“æ„ï¼‰ï¼Œåœ¨ä»»ä½•å…¶ä»–é€»è¾‘ä¹‹å‰
    init_database()

    from src.config.settings import get_settings

    try:
        settings = get_settings()
    except Exception as e:
        print(f"[ERROR] é…ç½®åŠ è½½å¤±è´¥: {e}")
        return

    print("=" * 50)
    print("PriceAction Backend Service (Async Architecture)")
    print("=" * 50)

    # âœ… æ­¥éª¤ 1: æ‰§è¡Œé¦–æ¬¡æ–°é—»æŠ“å–ï¼ˆæ­¤æ—¶è¡¨å·²ç»å­˜åœ¨ï¼Œä¸å†æŠ¥é”™ï¼‰
    print("\n[Step 1] æ‰§è¡Œé¦–æ¬¡æ–°é—»æŠ“å–...")
    try:
        from database import DatabaseManager

        db = DatabaseManager("./data.db")
        run_news_pipeline(db, settings.proxy)
        db.close()
        print("é¦–æ¬¡æ–°é—»æŠ“å–å®Œæˆ")
    except Exception as e:
        print(f"[WARNING] é¦–æ¬¡æ–°é—»æŠ“å–å¤±è´¥: {e}")

    # âœ… æ­¥éª¤ 2: æ‰§è¡Œå¸‚åœºåˆå§‹åˆ†æ
    print("\n[Step 2] æ‰§è¡Œåˆå§‹å¸‚åœºåˆ†æ...")
    try:
        run_analysis_cycle(settings)
    except Exception as e:
        print(f"[ERROR] åˆå§‹åˆ†æå¤±è´¥: {e}")
        import traceback

        traceback.print_exc()

    print("")
    print("åç«¯æœåŠ¡è¿è¡Œä¸­ (æŒ‰ Ctrl+C åœæ­¢)")
    print("")

    try:
        news_counter = 0

        while True:
            time.sleep(900)  # 15åˆ†é’Ÿ = 900ç§’

            # å¹¶å‘ä¿æŠ¤ï¼šé˜²æ­¢ä¸Šä¸€è½®åˆ†ææœªå®Œæˆæ—¶å¯åŠ¨æ–°ä¸€è½®
            if not _analysis_lock.acquire(blocking=False):
                print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] [SKIP] ä¸Šä¸€è½®åˆ†æä»åœ¨è¿›è¡Œä¸­")
                continue

            try:
                print("")
                print(f"[{time.strftime('%Y-%m-%d %H:%M:%S')}] æ‰§è¡Œå®šæ—¶åˆ†æ...")
                try:
                    run_analysis_cycle(settings)
                except Exception as e:
                    print(f"[ERROR] å®šæ—¶åˆ†æå¤±è´¥: {e}")

                # æ¯2ä¸ªå‘¨æœŸï¼ˆ30åˆ†é’Ÿï¼‰æ‰§è¡Œä¸€æ¬¡æ–°é—»æŠ“å–
                news_counter += 1
                if news_counter >= 2:
                    news_counter = 0
                    from database import DatabaseManager

                    db = DatabaseManager("./data.db")
                    run_news_pipeline(db, settings.proxy)
                    db.close()
            finally:
                _analysis_lock.release()  # ç¡®ä¿é‡Šæ”¾é”

    except KeyboardInterrupt:
        print("\næ­£åœ¨åœæ­¢åç«¯æœåŠ¡...")
        print("åç«¯æœåŠ¡å·²åœæ­¢")


def run_frontend():
    """å¯åŠ¨å‰ç«¯ç•Œé¢"""
    import streamlit.web.cli

    streamlit.web.cli.main_run(
        [
            "frontend/app.py",
            "--server.port",
            "8501",
            "--browser.gatherUsageStats",
            "false",
        ]
    )


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="PriceAction - AI Price Action Analyzer (Async)")
    parser.add_argument(
        "--mode",
        choices=["backend", "frontend", "both"],
        default="both",
        help="è¿è¡Œæ¨¡å¼: backend=åç«¯, frontend=å‰ç«¯, both=ä¸¤è€…",
    )

    args = parser.parse_args()

    if args.mode in ["backend", "both"]:
        run_backend()

    if args.mode in ["frontend", "both"]:
        run_frontend()
