"""
æ•°æ®åº“ç®¡ç†æ¨¡å—
è´Ÿè´£SQLiteæ•°æ®åº“çš„è¿æ¥ã€åˆå§‹åŒ–å’ŒCRUDæ“ä½œ
"""

import sqlite3
import json
import logging
from typing import Dict, List, Optional, Any
from datetime import datetime
from contextlib import contextmanager

logger = logging.getLogger(__name__)


class DatabaseManager:
    """æ•°æ®åº“ç®¡ç†å™¨"""

    def __init__(self, db_path: str = "./data.db"):
        self.db_path = db_path
        self._init_database()

    def _safe_parse_action_plan(self, data: Dict) -> Optional[Dict]:
        """å®‰å…¨è§£æactionPlanï¼Œå…¼å®¹æ—§æ•°æ®åº“"""
        try:
            raw = data.get("action_plan_json") or data.get("action_plan")
            return json.loads(raw) if raw else None
        except (TypeError, json.JSONDecodeError):
            return None

    @contextmanager
    def _get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        try:
            yield conn
            conn.commit()
        except Exception as e:
            conn.rollback()
            raise e
        finally:
            conn.close()

    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„"""
        try:
            with open("database/schema.sql", "r", encoding="utf-8") as f:
                schema = f.read()

            with self._get_connection() as conn:
                conn.executescript(schema)

            logger.info("Database initialized successfully")
        except Exception as e:
            logger.error(f"Failed to initialize database: {e}")
            raise

    def get_state(self, symbol: str, timeframe: str) -> Optional[Dict]:
        """
        è·å–æŒ‡å®šäº¤æ˜“å¯¹å’Œæ—¶é—´æ¡†æ¶çš„å½“å‰çŠ¶æ€

        Args:
            symbol: äº¤æ˜“å¯¹ï¼Œå¦‚ BTC/USDT
            timeframe: æ—¶é—´æ¡†æ¶ï¼Œå¦‚ 15m

        Returns:
            çŠ¶æ€å­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›None
        """
        try:
            with self._get_connection() as conn:
                cursor = conn.execute(
                    """SELECT * FROM states 
                       WHERE symbol = ? AND timeframe = ?""",
                    (symbol, timeframe),
                )
                row = cursor.fetchone()

                if row is None:
                    return None

                # ğŸ”§ å…³é”®ä¿®å¤ï¼šç«‹å³è½¬æ¢ä¸ºæ ‡å‡†å­—å…¸
                data = dict(row)

                return {
                    "symbol": data.get("symbol"),
                    "timeframe": data.get("timeframe"),
                    "last_updated": data.get("last_updated"),
                    "marketCycle": data.get("market_cycle"),
                    "activeNarrative": {
                        "pattern_name": data.get("active_pattern"),
                        "status": data.get("pattern_status"),
                        "key_levels": {
                            "entry_trigger": data.get("entry_trigger"),
                            "invalidation_level": data.get("invalidation_level"),
                            "profit_target_1": data.get("profit_target_1"),
                        },
                        "comment": data.get("pattern_comment"),
                        "probability": data.get("probability") or "",
                        "probability_value": data.get("probability_value") or 0.0,
                        "risk_reward": data.get("risk_reward") or 0.0,
                    },
                    "alternativeNarrative": {
                        "pattern_name": data.get("alternative_pattern"),
                        "trigger_condition": data.get("alternative_trigger"),
                    },
                    "raw_response": data.get("raw_response") or "",
                    "analysis_text": data.get("analysis_text") or "",
                    "actionPlan": self._safe_parse_action_plan(data),
                }
        except Exception as e:
            logger.error(f"Failed to get state for {symbol} {timeframe}: {e}")
            return None

    def save_state(self, symbol: str, timeframe: str, state: Dict) -> bool:
        """
        ä¿å­˜æˆ–æ›´æ–°çŠ¶æ€

        Args:
            symbol: äº¤æ˜“å¯¹
            timeframe: æ—¶é—´æ¡†æ¶
            state: çŠ¶æ€å­—å…¸

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            with self._get_connection() as conn:
                # å…ˆæ’å…¥ä¸´æ—¶è®°å½•ï¼ŒæˆåŠŸåæ›´æ–°ä¸»è®°å½•ï¼ˆåŸå­æ€§ï¼‰
                conn.execute("BEGIN TRANSACTION")

                # åˆ é™¤æ—§è®°å½•
                conn.execute(
                    "DELETE FROM states WHERE symbol = ? AND timeframe = ?",
                    (symbol, timeframe),
                )

                # è§£æçŠ¶æ€ç»“æ„
                active = state.get("activeNarrative", {})
                active_levels = active.get("key_levels", {})
                alternative = state.get("alternativeNarrative", {})
                action_plan = state.get("actionPlan")

                # è·å–æ–°å­—æ®µï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰
                probability = active.get("probability", "")
                probability_value = active.get("probability_value", 0.0)
                # è‡ªåŠ¨è®¡ç®—risk_rewardï¼ˆå¦‚æœæ²¡æœ‰æä¾›ï¼‰
                provided_rr = active.get("risk_reward", 0.0)
                if provided_rr and provided_rr > 0:
                    risk_reward = provided_rr
                else:
                    # ä»ä»·ä½è®¡ç®—ç›ˆäºæ¯”ï¼š|target - entry| / |entry - stop|
                    entry = active_levels.get("entry_trigger")
                    stop = active_levels.get("invalidation_level")
                    target = active_levels.get("profit_target_1")
                    if entry and stop and target and entry != stop:
                        risk = abs(entry - stop)
                        reward = abs(target - entry)
                        if risk > 0:
                            risk_reward = round(reward / risk, 2)
                        else:
                            risk_reward = 0.0
                    else:
                        risk_reward = 0.0

                # åºåˆ—åŒ–action_planä¸ºJSONå­—ç¬¦ä¸²
                action_plan_json = (
                    json.dumps(action_plan, ensure_ascii=False) if action_plan else None
                )

                # æ’å…¥æ–°è®°å½•
                conn.execute(
                    """INSERT INTO states (
                        symbol, timeframe, last_updated, market_cycle,
                        active_pattern, pattern_status, entry_trigger,
                        invalidation_level, profit_target_1, pattern_comment,
                        alternative_pattern, alternative_trigger, raw_response,
                        analysis_text, probability, probability_value, risk_reward,
                        action_plan
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                    (
                        symbol,
                        timeframe,
                        state.get(
                            "last_updated", int(datetime.now().timestamp() * 1000)
                        ),
                        state.get("marketCycle"),
                        active.get("pattern_name"),
                        active.get("status"),
                        active_levels.get("entry_trigger"),
                        active_levels.get("invalidation_level"),
                        active_levels.get("profit_target_1"),
                        active.get("comment"),
                        alternative.get("pattern_name"),
                        alternative.get("trigger_condition"),
                        state.get("raw_response", ""),
                        state.get("analysis_text", ""),
                        probability,
                        probability_value,
                        risk_reward,
                        action_plan_json,
                    ),
                )

                conn.commit()
                logger.info(f"State saved for {symbol} {timeframe}")
                return True

        except Exception as e:
            logger.error(f"Failed to save state for {symbol} {timeframe}: {e}")
            return False

    def log_history(self, symbol: str, timeframe: str, event: Dict) -> bool:
        """
        è®°å½•å†å²äº‹ä»¶

        Args:
            symbol: äº¤æ˜“å¯¹
            timeframe: æ—¶é—´æ¡†æ¶
            event: äº‹ä»¶å­—å…¸ï¼ŒåŒ…å«type, description, priceç­‰

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            with self._get_connection() as conn:
                conn.execute(
                    """INSERT INTO history (
                        symbol, timeframe, timestamp, event_type, price,
                        previous_status, new_status, description,
                        ai_recommendation, entry_price, stop_loss, target_price,
                        analysis_text, probability, probability_value, risk_reward
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                    (
                        symbol,
                        timeframe,
                        event.get("timestamp", int(datetime.now().timestamp() * 1000)),
                        event.get("type"),
                        event.get("price"),
                        event.get("previous_status"),
                        event.get("new_status"),
                        event.get("description"),
                        event.get("ai_recommendation"),
                        event.get("entry_price"),
                        event.get("stop_loss"),
                        event.get("target_price"),
                        event.get("analysis_text", ""),
                        event.get("probability", ""),
                        event.get("probability_value", 0.0),
                        event.get("risk_reward", 0.0),
                    ),
                )

            logger.info(f"History logged for {symbol} {timeframe}: {event.get('type')}")
            return True

        except Exception as e:
            logger.error(f"Failed to log history for {symbol} {timeframe}: {e}")
            return False

    def get_history(self, symbol: str, timeframe: str, limit: int = 100) -> List[Dict]:
        """
        è·å–å†å²è®°å½•

        Args:
            symbol: äº¤æ˜“å¯¹
            timeframe: æ—¶é—´æ¡†æ¶
            limit: è¿”å›è®°å½•æ•°ä¸Šé™

        Returns:
            å†å²è®°å½•åˆ—è¡¨
        """
        try:
            with self._get_connection() as conn:
                cursor = conn.execute(
                    """SELECT * FROM history 
                       WHERE symbol = ? AND timeframe = ?
                       ORDER BY timestamp DESC
                       LIMIT ?""",
                    (symbol, timeframe, limit),
                )

                rows = cursor.fetchall()
                return [dict(row) for row in rows]

        except Exception as e:
            logger.error(f"Failed to get history for {symbol} {timeframe}: {e}")
            return []

    def get_all_states(self) -> List[Dict]:
        """
        è·å–æ‰€æœ‰å½“å‰çŠ¶æ€

        Returns:
            æ‰€æœ‰çŠ¶æ€åˆ—è¡¨
        """
        try:
            with self._get_connection() as conn:
                cursor = conn.execute("SELECT * FROM states ORDER BY symbol, timeframe")
                rows = cursor.fetchall()

                states = []
                for row in rows:
                    # ğŸ”§ å…³é”®ä¿®å¤ï¼šç«‹å³è½¬æ¢ä¸ºæ ‡å‡†å­—å…¸
                    data = dict(row)

                    states.append(
                        {
                            "symbol": data.get("symbol"),
                            "timeframe": data.get("timeframe"),
                            "last_updated": data.get("last_updated"),
                            "marketCycle": data.get("market_cycle"),
                            "activeNarrative": {
                                "pattern_name": data.get("active_pattern"),
                                "status": data.get("pattern_status"),
                                "key_levels": {
                                    "entry_trigger": data.get("entry_trigger"),
                                    "invalidation_level": data.get(
                                        "invalidation_level"
                                    ),
                                    "profit_target_1": data.get("profit_target_1"),
                                },
                                "comment": data.get("pattern_comment"),
                                "probability": data.get("probability") or "",
                                "probability_value": data.get("probability_value")
                                or 0.0,
                                "risk_reward": data.get("risk_reward") or 0.0,
                                "risk_reward_ratio": data.get("risk_reward") or 0.0,
                            },
                            "alternativeNarrative": {
                                "pattern_name": data.get("alternative_pattern"),
                                "trigger_condition": data.get("alternative_trigger"),
                            },
                            "analysis_text": data.get("analysis_text") or "",
                            "actionPlan": self._safe_parse_action_plan(data),
                        }
                    )

                return states

        except Exception as e:
            logger.error(f"Failed to get all states: {e}")
            return []

    def log_system(
        self, level: str, component: str, message: str, exception: Optional[str] = None
    ) -> bool:
        """
        è®°å½•ç³»ç»Ÿæ—¥å¿—

        Args:
            level: æ—¥å¿—çº§åˆ« DEBUG/INFO/WARNING/ERROR
            component: ç»„ä»¶åç§°
            message: æ—¥å¿—æ¶ˆæ¯
            exception: å¼‚å¸¸ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            with self._get_connection() as conn:
                conn.execute(
                    """INSERT INTO logs (timestamp, level, component, message, exception)
                       VALUES (?, ?, ?, ?, ?)""",
                    (
                        int(datetime.now().timestamp() * 1000),
                        level,
                        component,
                        message,
                        exception,
                    ),
                )
            return True
        except Exception as e:
            # æ—¥å¿—è®°å½•å¤±è´¥ä¸æŠ›å¼‚å¸¸ï¼Œé¿å…å¾ªç¯
            print(f"Failed to log to database: {e}")
            return False

    def get_multi_timeframe_state(self, symbol: str, timeframe: str) -> Optional[Dict]:
        """
        ä»multi_timeframe_statesè¡¨è·å–çŠ¶æ€ï¼ˆå¤šå‘¨æœŸä¸“ç”¨ï¼‰

        Args:
            symbol: äº¤æ˜“å¯¹
            timeframe: æ—¶é—´æ¡†æ¶

        Returns:
            çŠ¶æ€å­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›None
        """
        try:
            with self._get_connection() as conn:
                cursor = conn.execute(
                    """SELECT * FROM multi_timeframe_states
                       WHERE symbol = ? AND timeframe = ?""",
                    (symbol, timeframe),
                )
                row = cursor.fetchone()
                if row is None:
                    return None

                # ğŸ”§ å…³é”®ä¿®å¤ï¼šç«‹å³è½¬æ¢ä¸ºæ ‡å‡†å­—å…¸
                data = dict(row)

                return {
                    "symbol": data.get("symbol"),
                    "timeframe": data.get("timeframe"),
                    "last_updated": data.get("last_updated"),
                    "marketCycle": data.get("market_cycle"),
                    "activeNarrative": {
                        "pattern_name": data.get("active_pattern"),
                        "status": data.get("pattern_status"),
                        "key_levels": {
                            "entry_trigger": data.get("entry_trigger"),
                            "invalidation_level": data.get("invalidation_level"),
                            "profit_target_1": data.get("profit_target_1"),
                        },
                        "comment": data.get("pattern_comment"),
                        "probability": data.get("probability") or "",
                        "probability_value": data.get("probability_value") or 0.0,
                        "risk_reward": data.get("risk_reward") or 0.0,
                    },
                    "alternativeNarrative": {
                        "pattern_name": data.get("alternative_pattern"),
                        "trigger_condition": data.get("alternative_trigger"),
                    },
                    "raw_response": data.get("raw_response") or "",
                    "analysis_text": data.get("analysis_text") or "",
                    "timeframe_weight": data.get("timeframe_weight") or 1.0,
                    "parent_alignment": data.get("parent_alignment") or "NEUTRAL",
                    "actionPlan": self._safe_parse_action_plan(data),
                }
        except Exception as e:
            logger.error(f"Failed to get MTF state for {symbol} {timeframe}: {e}")
            return None

    def save_multi_timeframe_state(
        self, symbol: str, timeframe: str, state: Dict
    ) -> bool:
        """
        ä¿å­˜å¤šå‘¨æœŸçŠ¶æ€åˆ°multi_timeframe_statesè¡¨

        Args:
            symbol: äº¤æ˜“å¯¹
            timeframe: æ—¶é—´æ¡†æ¶
            state: çŠ¶æ€å­—å…¸

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            with self._get_connection() as conn:
                conn.execute("BEGIN TRANSACTION")

                # åˆ é™¤æ—§è®°å½•
                conn.execute(
                    "DELETE FROM multi_timeframe_states WHERE symbol = ? AND timeframe = ?",
                    (symbol, timeframe),
                )

                # æå–å­—æ®µï¼ˆå¤ç”¨ç°æœ‰é€»è¾‘ï¼‰
                active = state.get("activeNarrative", {})
                active_levels = active.get("key_levels", {})
                alternative = state.get("alternativeNarrative", {})
                action_plan = state.get("actionPlan")

                # åºåˆ—åŒ–action_planä¸ºJSONå­—ç¬¦ä¸²
                action_plan_json = (
                    json.dumps(action_plan, ensure_ascii=False) if action_plan else None
                )

                conn.execute(
                    """INSERT INTO multi_timeframe_states (
                        symbol, timeframe, last_updated, market_cycle,
                        active_pattern, pattern_status, entry_trigger,
                        invalidation_level, profit_target_1, pattern_comment,
                        alternative_pattern, alternative_trigger, raw_response,
                        analysis_text, probability, probability_value, risk_reward,
                        timeframe_weight, parent_alignment, action_plan
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                    (
                        symbol,
                        timeframe,
                        state.get(
                            "last_updated", int(datetime.now().timestamp() * 1000)
                        ),
                        state.get("marketCycle"),
                        active.get("pattern_name"),
                        active.get("status"),
                        active_levels.get("entry_trigger"),
                        active_levels.get("invalidation_level"),
                        active_levels.get("profit_target_1"),
                        active.get("comment"),
                        alternative.get("pattern_name"),
                        alternative.get("trigger_condition"),
                        state.get("raw_response", ""),
                        state.get("analysis_text", ""),
                        active.get("probability", ""),
                        active.get("probability_value", 0.0),
                        active.get("risk_reward", 0.0),
                        state.get("timeframe_weight", 1.0),
                        state.get("parent_alignment", "NEUTRAL"),
                        action_plan_json,
                    ),
                )
                conn.commit()
                return True
        except Exception as e:
            logger.error(f"Failed to save MTF state: {e}")
            return False

    def get_all_timeframes_for_symbol(self, symbol: str) -> List[Dict]:
        """
        è·å–æŸä¸ªäº¤æ˜“å¯¹çš„æ‰€æœ‰æ—¶é—´æ¡†æ¶çŠ¶æ€

        Args:
            symbol: äº¤æ˜“å¯¹

        Returns:
            æ‰€æœ‰æ—¶é—´æ¡†æ¶çŠ¶æ€åˆ—è¡¨
        """
        try:
            with self._get_connection() as conn:
                cursor = conn.execute(
                    """SELECT * FROM multi_timeframe_states
                       WHERE symbol = ? ORDER BY timeframe""",
                    (symbol,),
                )
                rows = cursor.fetchall()

                result = []
                for row in rows:
                    # ğŸ”§ å…³é”®ä¿®å¤ï¼šç«‹å³è½¬æ¢ä¸ºæ ‡å‡†å­—å…¸
                    data = dict(row)

                    result.append(
                        {
                            "symbol": data.get("symbol"),
                            "timeframe": data.get("timeframe"),
                            "last_updated": data.get("last_updated"),
                            "marketCycle": data.get("market_cycle"),
                            "activeNarrative": {
                                "pattern_name": data.get("active_pattern"),
                                "status": data.get("pattern_status"),
                                "key_levels": {
                                    "entry_trigger": data.get("entry_trigger"),
                                    "invalidation_level": data.get(
                                        "invalidation_level"
                                    ),
                                    "profit_target_1": data.get("profit_target_1"),
                                },
                                "comment": data.get("pattern_comment"),
                                "probability": data.get("probability") or "",
                                "probability_value": data.get("probability_value")
                                or 0.0,
                                "risk_reward": data.get("risk_reward") or 0.0,
                            },
                            "alternativeNarrative": {
                                "pattern_name": data.get("alternative_pattern"),
                                "trigger_condition": data.get("alternative_trigger"),
                            },
                            "raw_response": data.get("raw_response") or "",
                            "analysis_text": data.get("analysis_text") or "",
                            "timeframe_weight": data.get("timeframe_weight") or 1.0,
                            "parent_alignment": data.get("parent_alignment")
                            or "NEUTRAL",
                            "actionPlan": self._safe_parse_action_plan(data),
                        }
                    )

                return result
        except Exception as e:
            logger.error(f"Failed to get all timeframes for {symbol}: {e}")
            return []

    def save_consensus(self, symbol: str, consensus: Dict) -> bool:
        """
        ä¿å­˜å‘¨æœŸä¸€è‡´æ€§åˆ†æç»“æœ

        Args:
            symbol: äº¤æ˜“å¯¹
            consensus: ä¸€è‡´æ€§åˆ†æå­—å…¸

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            with self._get_connection() as conn:
                conn.execute(
                    """INSERT INTO timeframe_consensus (
                        symbol, timestamp, consensus_direction, confidence,
                        aligned_timeframes, conflicting_timeframes, recommendation,
                        bullish_score, bearish_score
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                    (
                        symbol,
                        consensus.get(
                            "timestamp", int(datetime.now().timestamp() * 1000)
                        ),
                        consensus.get("direction", "NEUTRAL"),
                        consensus.get("confidence", 0.0),
                        json.dumps(consensus.get("aligned", [])),
                        json.dumps(consensus.get("conflicting", [])),
                        consensus.get("recommendation", ""),
                        consensus.get("bullish_score", 0.0),
                        consensus.get("bearish_score", 0.0),
                    ),
                )
                return True
        except Exception as e:
            logger.error(f"Failed to save consensus: {e}")
            return False

    def get_latest_consensus(self, symbol: str) -> Optional[Dict]:
        """
        è·å–æœ€æ–°çš„å‘¨æœŸä¸€è‡´æ€§ç»“æœ

        Args:
            symbol: äº¤æ˜“å¯¹

        Returns:
            ä¸€è‡´æ€§åˆ†æå­—å…¸ï¼Œå¦‚æœä¸å­˜åœ¨è¿”å›None
        """
        try:
            with self._get_connection() as conn:
                cursor = conn.execute(
                    """SELECT * FROM timeframe_consensus
                       WHERE symbol = ? ORDER BY timestamp DESC LIMIT 1""",
                    (symbol,),
                )
                row = cursor.fetchone()
                if row is None:
                    return None
                return {
                    "symbol": row["symbol"],
                    "timestamp": row["timestamp"],
                    "direction": row["consensus_direction"],
                    "confidence": row["confidence"],
                    "aligned": (
                        json.loads(row["aligned_timeframes"])
                        if row["aligned_timeframes"]
                        else []
                    ),
                    "conflicting": (
                        json.loads(row["conflicting_timeframes"])
                        if row["conflicting_timeframes"]
                        else []
                    ),
                    "recommendation": row["recommendation"],
                    "bullish_score": row["bullish_score"],
                    "bearish_score": row["bearish_score"],
                }
        except Exception as e:
            logger.error(f"Failed to get consensus for {symbol}: {e}")
            return None

    def cleanup_old_logs(self, days: int = 30) -> int:
        """
        æ¸…ç†æ—§æ—¥å¿—

        Args:
            days: ä¿ç•™å¤©æ•°

        Returns:
            åˆ é™¤çš„è®°å½•æ•°
        """
        try:
            cutoff = int((datetime.now().timestamp() - days * 86400) * 1000)

            with self._get_connection() as conn:
                cursor = conn.execute("DELETE FROM logs WHERE timestamp < ?", (cutoff,))
                deleted = cursor.rowcount

                cursor = conn.execute(
                    "DELETE FROM history WHERE timestamp < ?", (cutoff,)
                )
                deleted += cursor.rowcount

            logger.info(f"Cleaned up {deleted} old records")
            return deleted

        except Exception as e:
            logger.error(f"Failed to cleanup old logs: {e}")
            return 0

    # ==================== Phase 4: æ™ºèƒ½ä¿¡å·ç³»ç»Ÿæ¥å£ ====================

    def save_signal(self, signal: Dict) -> int:
        """
        ä¿å­˜äº¤æ˜“ä¿¡å·

        Args:
            signal: ä¿¡å·å­—å…¸ï¼ŒåŒ…å«æ‰€æœ‰ä¿¡å·ä¿¡æ¯

        Returns:
            æ’å…¥çš„ä¿¡å·ID
        """
        try:
            with self._get_connection() as conn:
                cursor = conn.execute(
                    """INSERT INTO trading_signals (
                        symbol, timeframe, timestamp, signal_level, signal_type,
                        confidence, pattern_name, pattern_status, pattern_quality,
                        entry_trigger, stop_loss, profit_target_1, profit_target_2,
                        risk_reward_ratio, market_cycle, consensus_score,
                        ai_analysis, raw_response, signal_checks,
                        volume_ratio, volume_significance
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                    (
                        signal.get("symbol"),
                        signal.get("timeframe"),
                        signal.get("timestamp", int(datetime.now().timestamp() * 1000)),
                        signal.get("signal_level"),
                        signal.get("signal_type"),
                        signal.get("confidence", 0),
                        signal.get("pattern_name"),
                        signal.get("pattern_status"),
                        signal.get("pattern_quality", 3),
                        signal.get("entry_trigger"),
                        signal.get("stop_loss"),
                        signal.get("profit_target_1"),
                        signal.get("profit_target_2"),
                        # ä¼˜å…ˆä½¿ç”¨ risk_rewardï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨ risk_reward_ratio
                        signal.get("risk_reward", signal.get("risk_reward_ratio", 0.0)),
                        signal.get("market_cycle"),
                        signal.get("consensus_score", 0.0),
                        signal.get("ai_analysis", ""),
                        signal.get("raw_response", ""),
                        json.dumps(signal.get("signal_checks", {})),
                        signal.get("volume_ratio", 1.0),
                        signal.get("volume_significance", "normal"),
                    ),
                )
                signal_id = cursor.lastrowid
                if signal_id is None:
                    signal_id = -1
                logger.info(
                    f"Signal saved: ID={signal_id}, {signal.get('symbol')} {signal.get('signal_level')}"
                )
                return signal_id
        except Exception as e:
            logger.error(f"Failed to save signal: {e}")
            return -1

    def get_pending_signals(self, symbol: str = "", timeframe: str = "") -> List[Dict]:
        """
        è·å–æœªå®Œç»“çš„ä¿¡å·ï¼ˆoutcomeä¸ºNULLçš„è®°å½•ï¼‰

        Args:
            symbol: å¯é€‰ï¼Œç­›é€‰ç‰¹å®šäº¤æ˜“å¯¹
            timeframe: å¯é€‰ï¼Œç­›é€‰ç‰¹å®šæ—¶é—´æ¡†æ¶

        Returns:
            æœªå®Œç»“ä¿¡å·åˆ—è¡¨
        """
        try:
            with self._get_connection() as conn:
                query = """SELECT * FROM trading_signals WHERE outcome IS NULL"""
                params = []

                if symbol:
                    query += " AND symbol = ?"
                    params.append(symbol)
                if timeframe:
                    query += " AND timeframe = ?"
                    params.append(timeframe)

                query += " ORDER BY timestamp DESC"

                cursor = conn.execute(query, params)
                rows = cursor.fetchall()

                signals = []
                for row in rows:
                    signal = dict(row)
                    # è§£æJSONå­—æ®µ
                    if signal.get("signal_checks"):
                        try:
                            signal["signal_checks"] = json.loads(
                                signal["signal_checks"]
                            )
                        except:
                            signal["signal_checks"] = {}
                    signals.append(signal)

                return signals
        except Exception as e:
            logger.error(f"Failed to get pending signals: {e}")
            return []

    def update_signal_outcome(
        self,
        signal_id: int,
        outcome: str,
        outcome_price: float = 0.0,
        pnl_percent: float = 0.0,
    ) -> bool:
        """
        æ›´æ–°ä¿¡å·ç»“æœ

        Args:
            signal_id: ä¿¡å·ID
            outcome: ç»“æœ (WIN/LOSS/EXPIRED)
            outcome_price: å‡ºåœºä»·æ ¼
            pnl_percent: ç›ˆäºç™¾åˆ†æ¯”

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            with self._get_connection() as conn:
                conn.execute(
                    """UPDATE trading_signals 
                       SET outcome = ?, outcome_price = ?, outcome_timestamp = ?, pnl_percent = ?
                       WHERE id = ?""",
                    (
                        outcome,
                        outcome_price,
                        int(datetime.now().timestamp() * 1000),
                        pnl_percent,
                        signal_id,
                    ),
                )
                logger.info(
                    f"Signal outcome updated: ID={signal_id}, outcome={outcome}, PnL={pnl_percent}%"
                )
                return True
        except Exception as e:
            logger.error(f"Failed to update signal outcome: {e}")
            return False

    def get_signals_by_pattern(self, pattern_name: str, limit: int = 100) -> List[Dict]:
        """
        è·å–ç‰¹å®šå½¢æ€çš„å†å²ä¿¡å·

        Args:
            pattern_name: å½¢æ€åç§°
            limit: è¿”å›æ•°é‡é™åˆ¶

        Returns:
            ä¿¡å·åˆ—è¡¨
        """
        try:
            with self._get_connection() as conn:
                cursor = conn.execute(
                    """SELECT * FROM trading_signals 
                       WHERE pattern_name = ? 
                       ORDER BY timestamp DESC 
                       LIMIT ?""",
                    (pattern_name, limit),
                )
                rows = cursor.fetchall()
                return [dict(row) for row in rows]
        except Exception as e:
            logger.error(f"Failed to get signals by pattern: {e}")
            return []

    def get_all_signals(self, limit: int = 100, hours: int = 0) -> List[Dict]:
        """
        è·å–æ‰€æœ‰äº¤æ˜“ä¿¡å·ï¼ˆç”¨äºå‰ç«¯ä¿¡å·é¢æ¿ï¼‰

        Args:
            limit: è¿”å›æ•°é‡é™åˆ¶
            hours: åªè¿”å›æœ€è¿‘Nå°æ—¶çš„ä¿¡å·ï¼ŒNoneè¡¨ç¤ºä¸é™åˆ¶

        Returns:
            ä¿¡å·åˆ—è¡¨
        """
        try:
            with self._get_connection() as conn:
                if hours:
                    # è®¡ç®—æ—¶é—´æˆ³
                    from datetime import datetime, timedelta

                    cutoff = int(
                        (datetime.now() - timedelta(hours=hours)).timestamp() * 1000
                    )
                    cursor = conn.execute(
                        """SELECT * FROM trading_signals 
                           WHERE timestamp > ? 
                           ORDER BY timestamp DESC 
                           LIMIT ?""",
                        (cutoff, limit),
                    )
                else:
                    cursor = conn.execute(
                        """SELECT * FROM trading_signals 
                           ORDER BY timestamp DESC 
                           LIMIT ?""",
                        (limit,),
                    )
                rows = cursor.fetchall()

                signals = []
                for row in rows:
                    signal = dict(row)
                    # è§£æJSONå­—æ®µ
                    if signal.get("signal_checks"):
                        try:
                            signal["signal_checks"] = json.loads(
                                signal["signal_checks"]
                            )
                        except:
                            signal["signal_checks"] = {}
                    signals.append(signal)

                return signals
        except Exception as e:
            logger.error(f"Failed to get all signals: {e}")
            return []

    def log_warning_event(self, warning: Dict) -> bool:
        """
        è®°å½•è­¦å‘Šäº‹ä»¶

        Args:
            warning: è­¦å‘Šäº‹ä»¶å­—å…¸

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            with self._get_connection() as conn:
                conn.execute(
                    """INSERT INTO warning_events (
                        symbol, timeframe, timestamp, warning_type, priority,
                        description, old_state, new_state, trigger_price,
                        current_price, related_signal_id
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                    (
                        warning.get("symbol", ""),
                        warning.get("timeframe", ""),
                        warning.get(
                            "timestamp", int(datetime.now().timestamp() * 1000)
                        ),
                        warning.get("warning_type", ""),
                        warning.get("priority", "medium"),
                        warning.get("description", ""),
                        json.dumps(warning.get("old_state", {})),
                        json.dumps(warning.get("new_state", {})),
                        warning.get("trigger_price", 0.0),
                        warning.get("current_price", 0.0),
                        warning.get("related_signal_id", 0),
                    ),
                )
                logger.info(
                    f"Warning logged: {warning.get('symbol')} {warning.get('warning_type')}"
                )
                return True
        except Exception as e:
            logger.error(f"Failed to log warning event: {e}")
            return False

    def get_recent_warnings(self, symbol: str = "", hours: int = 24) -> List[Dict]:
        """
        è·å–æœ€è¿‘çš„è­¦å‘Šäº‹ä»¶

        Args:
            symbol: å¯é€‰ï¼Œç­›é€‰ç‰¹å®šäº¤æ˜“å¯¹
            hours: æŸ¥è¯¢è¿‡å»å¤šå°‘å°æ—¶

        Returns:
            è­¦å‘Šäº‹ä»¶åˆ—è¡¨
        """
        try:
            cutoff = int((datetime.now().timestamp() - hours * 3600) * 1000)

            with self._get_connection() as conn:
                if symbol:
                    cursor = conn.execute(
                        """SELECT * FROM warning_events 
                           WHERE symbol = ? AND timestamp > ? 
                           ORDER BY timestamp DESC""",
                        (symbol, cutoff),
                    )
                else:
                    cursor = conn.execute(
                        """SELECT * FROM warning_events 
                           WHERE timestamp > ? 
                           ORDER BY timestamp DESC""",
                        (cutoff,),
                    )
                rows = cursor.fetchall()

                warnings = []
                for row in rows:
                    warning = dict(row)
                    # è§£æJSONå­—æ®µ
                    for field in ["old_state", "new_state"]:
                        if warning.get(field):
                            try:
                                warning[field] = json.loads(warning[field])
                            except:
                                warning[field] = {}
                    warnings.append(warning)

                return warnings
        except Exception as e:
            logger.error(f"Failed to get recent warnings: {e}")
            return []

    def update_pattern_statistics(self, stats: Dict) -> bool:
        """
        æ›´æ–°å½¢æ€ç»Ÿè®¡ä¿¡æ¯

        Args:
            stats: ç»Ÿè®¡æ•°æ®å­—å…¸

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            with self._get_connection() as conn:
                conn.execute(
                    """INSERT OR REPLACE INTO pattern_statistics (
                        pattern_name, total_signals, wins, losses, pending,
                        win_rate, avg_pnl_percent, avg_risk_reward,
                        by_market_cycle, last_updated
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                    (
                        stats.get("pattern_name"),
                        stats.get("total_signals", 0),
                        stats.get("wins", 0),
                        stats.get("losses", 0),
                        stats.get("pending", 0),
                        stats.get("win_rate", 0.0),
                        stats.get("avg_pnl_percent", 0.0),
                        stats.get("avg_risk_reward", 0.0),
                        json.dumps(stats.get("by_market_cycle", {})),
                        int(datetime.now().timestamp() * 1000),
                    ),
                )
                return True
        except Exception as e:
            logger.error(f"Failed to update pattern statistics: {e}")
            return False

    def get_pattern_statistics(self, pattern_name: str = "") -> Dict:
        """
        è·å–å½¢æ€ç»Ÿè®¡ä¿¡æ¯

        Args:
            pattern_name: å¯é€‰ï¼Œç‰¹å®šå½¢æ€åç§°ã€‚ä¸ºNoneè¿”å›æ‰€æœ‰å½¢æ€ç»Ÿè®¡

        Returns:
            ç»Ÿè®¡æ•°æ®å­—å…¸æˆ–åˆ—è¡¨
        """
        try:
            with self._get_connection() as conn:
                if pattern_name:
                    cursor = conn.execute(
                        "SELECT * FROM pattern_statistics WHERE pattern_name = ?",
                        (pattern_name,),
                    )
                    row = cursor.fetchone()
                    if row:
                        stats = dict(row)
                        if stats.get("by_market_cycle"):
                            try:
                                stats["by_market_cycle"] = json.loads(
                                    stats["by_market_cycle"]
                                )
                            except:
                                stats["by_market_cycle"] = {}
                        return stats
                    return {}
                else:
                    cursor = conn.execute(
                        "SELECT * FROM pattern_statistics ORDER BY win_rate DESC"
                    )
                    rows = cursor.fetchall()

                    all_stats = []
                    for row in rows:
                        stats = dict(row)
                        if stats.get("by_market_cycle"):
                            try:
                                stats["by_market_cycle"] = json.loads(
                                    stats["by_market_cycle"]
                                )
                            except:
                                stats["by_market_cycle"] = {}
                        all_stats.append(stats)

                    # è¿”å›åŒ…è£…åçš„å­—å…¸ï¼Œä¿æŒä¸€è‡´æ€§
                    return {"patterns": all_stats, "count": len(all_stats)}
        except Exception as e:
            logger.error(f"Failed to get pattern statistics: {e}")
            return {}

    # ==================== äº¤æ˜“è®°å½•è¿½è¸ªæ¥å£ ====================

    def create_trade(self, trade: Dict) -> int:
        """
        åˆ›å»ºæ–°çš„äº¤æ˜“è®°å½•ï¼ˆå»ºä»“ï¼‰

        Args:
            trade: äº¤æ˜“å­—å…¸ï¼ŒåŒ…å«ï¼š
                - symbol: äº¤æ˜“å¯¹
                - timeframe: æ—¶é—´æ¡†æ¶
                - direction: LONG/SHORT
                - entry_price: å…¥åœºä»·æ ¼
                - stop_loss: æ­¢æŸä»·æ ¼
                - take_profit_1: ç¬¬ä¸€ç›®æ ‡ä½
                - take_profit_2: ç¬¬äºŒç›®æ ‡ä½ï¼ˆå¯é€‰ï¼‰
                - entry_signal_id: å…³è”çš„ä¿¡å·ID
                - pattern_name: å½¢æ€åç§°
                - market_cycle: å¸‚åœºå‘¨æœŸ
                - ai_recommendation: AIå»ºè®®æ–‡æœ¬

        Returns:
            äº¤æ˜“è®°å½•ID
        """
        try:
            with self._get_connection() as conn:
                cursor = conn.execute(
                    """INSERT INTO trades (
                        symbol, timeframe, direction, status,
                        entry_price, entry_timestamp, entry_signal_id,
                        stop_loss, take_profit_1, take_profit_2,
                        pattern_name, market_cycle, ai_recommendation,
                        last_check_timestamp, notes
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                    (
                        trade.get("symbol"),
                        trade.get("timeframe"),
                        trade.get("direction", "LONG"),
                        "OPEN",
                        trade.get("entry_price"),
                        trade.get(
                            "entry_timestamp", int(datetime.now().timestamp() * 1000)
                        ),
                        trade.get("entry_signal_id"),
                        trade.get("stop_loss"),
                        trade.get("take_profit_1"),
                        trade.get("take_profit_2"),
                        trade.get("pattern_name", ""),
                        trade.get("market_cycle", ""),
                        trade.get("ai_recommendation", ""),
                        int(datetime.now().timestamp() * 1000),
                        trade.get("notes", ""),
                    ),
                )
                trade_id = cursor.lastrowid
                logger.info(
                    f"Trade created: ID={trade_id}, {trade.get('symbol')} "
                    f"Entry={trade.get('entry_price')}, SL={trade.get('stop_loss')}"
                )
                return trade_id if trade_id else -1
        except Exception as e:
            logger.error(f"Failed to create trade: {e}")
            return -1

    def close_trade(
        self,
        trade_id: int,
        exit_price: float,
        exit_reason: str,
        pnl_absolute: float = 0.0,
        pnl_percent: float = 0.0,
        notes: str = "",
    ) -> bool:
        """
        å¹³ä»“äº¤æ˜“è®°å½•

        Args:
            trade_id: äº¤æ˜“ID
            exit_price: å‡ºåœºä»·æ ¼
            exit_reason: å¹³ä»“åŸå› ï¼ˆTP1/TP2/SL/EXPIRED/MANUALï¼‰
            pnl_absolute: ç»å¯¹ç›ˆäº
            pnl_percent: ç™¾åˆ†æ¯”ç›ˆäº
            notes: å¤‡æ³¨

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            with self._get_connection() as conn:
                conn.execute(
                    """UPDATE trades 
                       SET status = 'CLOSED',
                           exit_price = ?,
                           exit_timestamp = ?,
                           exit_reason = ?,
                           pnl_absolute = ?,
                           pnl_percent = ?,
                           notes = CASE WHEN notes = '' THEN ? ELSE notes || '; ' || ? END,
                           updated_at = ?
                       WHERE id = ?""",
                    (
                        exit_price,
                        int(datetime.now().timestamp() * 1000),
                        exit_reason,
                        pnl_absolute,
                        pnl_percent,
                        notes,
                        notes,
                        int(datetime.now().timestamp() * 1000),
                        trade_id,
                    ),
                )
                logger.info(
                    f"Trade closed: ID={trade_id}, Exit={exit_price}, "
                    f"Reason={exit_reason}, PnL={pnl_percent:.2f}%"
                )
                return True
        except Exception as e:
            logger.error(f"Failed to close trade {trade_id}: {e}")
            return False

    def get_open_trades(self, symbol: str = "") -> List[Dict]:
        """
        è·å–æ‰€æœ‰å¼€ä»“ä¸­çš„äº¤æ˜“

        Args:
            symbol: å¯é€‰ï¼Œç­›é€‰ç‰¹å®šäº¤æ˜“å¯¹

        Returns:
            å¼€ä»“äº¤æ˜“åˆ—è¡¨
        """
        try:
            with self._get_connection() as conn:
                if symbol:
                    cursor = conn.execute(
                        """SELECT * FROM trades 
                           WHERE status = 'OPEN' AND symbol = ?
                           ORDER BY entry_timestamp DESC""",
                        (symbol,),
                    )
                else:
                    cursor = conn.execute(
                        """SELECT * FROM trades 
                           WHERE status = 'OPEN'
                           ORDER BY entry_timestamp DESC"""
                    )
                rows = cursor.fetchall()
                return [dict(row) for row in rows]
        except Exception as e:
            logger.error(f"Failed to get open trades: {e}")
            return []

    def get_trade_by_id(self, trade_id: int) -> Optional[Dict]:
        """
        è·å–æŒ‡å®šäº¤æ˜“è®°å½•

        Args:
            trade_id: äº¤æ˜“ID

        Returns:
            äº¤æ˜“å­—å…¸æˆ–None
        """
        try:
            with self._get_connection() as conn:
                cursor = conn.execute(
                    "SELECT * FROM trades WHERE id = ?",
                    (trade_id,),
                )
                row = cursor.fetchone()
                return dict(row) if row else None
        except Exception as e:
            logger.error(f"Failed to get trade {trade_id}: {e}")
            return None

    def get_all_trades(
        self, limit: int = 100, status: str = "", symbol: str = ""
    ) -> List[Dict]:
        """
        è·å–äº¤æ˜“è®°å½•åˆ—è¡¨

        Args:
            limit: è¿”å›æ•°é‡é™åˆ¶
            status: å¯é€‰ï¼Œç­›é€‰çŠ¶æ€ï¼ˆOPEN/CLOSED/EXPIREDï¼‰
            symbol: å¯é€‰ï¼Œç­›é€‰äº¤æ˜“å¯¹

        Returns:
            äº¤æ˜“åˆ—è¡¨
        """
        try:
            with self._get_connection() as conn:
                query = "SELECT * FROM trades WHERE 1=1"
                params = []

                if status:
                    query += " AND status = ?"
                    params.append(status)
                if symbol:
                    query += " AND symbol = ?"
                    params.append(symbol)

                query += " ORDER BY entry_timestamp DESC LIMIT ?"
                params.append(limit)

                cursor = conn.execute(query, params)
                rows = cursor.fetchall()
                return [dict(row) for row in rows]
        except Exception as e:
            logger.error(f"Failed to get trades: {e}")
            return []

    def update_trade_check_time(self, trade_id: int) -> bool:
        """
        æ›´æ–°äº¤æ˜“æœ€åæ£€æŸ¥æ—¶é—´

        Args:
            trade_id: äº¤æ˜“ID

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            with self._get_connection() as conn:
                conn.execute(
                    """UPDATE trades 
                       SET last_check_timestamp = ?
                       WHERE id = ?""",
                    (int(datetime.now().timestamp() * 1000), trade_id),
                )
                return True
        except Exception as e:
            logger.error(f"Failed to update trade check time: {e}")
            return False

    def get_trades_statistics(self) -> Dict:
        """
        è·å–äº¤æ˜“ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡æ•°æ®å­—å…¸
        """
        try:
            with self._get_connection() as conn:
                # æ€»äº¤æ˜“æ•°
                cursor = conn.execute("SELECT COUNT(*) FROM trades")
                total = cursor.fetchone()[0]

                # å¼€ä»“ä¸­
                cursor = conn.execute(
                    "SELECT COUNT(*) FROM trades WHERE status = 'OPEN'"
                )
                open_count = cursor.fetchone()[0]

                # å·²å¹³ä»“
                cursor = conn.execute(
                    "SELECT COUNT(*) FROM trades WHERE status = 'CLOSED'"
                )
                closed_count = cursor.fetchone()[0]

                # ç›ˆåˆ©äº¤æ˜“
                cursor = conn.execute(
                    "SELECT COUNT(*), AVG(pnl_percent) FROM trades WHERE pnl_percent > 0"
                )
                row = cursor.fetchone()
                wins = row[0] if row else 0
                avg_win = row[1] if row and row[1] else 0

                # äºæŸäº¤æ˜“
                cursor = conn.execute(
                    "SELECT COUNT(*), AVG(pnl_percent) FROM trades WHERE pnl_percent < 0"
                )
                row = cursor.fetchone()
                losses = row[0] if row else 0
                avg_loss = row[1] if row and row[1] else 0

                # è®¡ç®—èƒœç‡
                win_rate = (wins / (wins + losses) * 100) if (wins + losses) > 0 else 0

                return {
                    "total_trades": total,
                    "open_trades": open_count,
                    "closed_trades": closed_count,
                    "wins": wins,
                    "losses": losses,
                    "win_rate": win_rate,
                    "avg_win_percent": avg_win,
                    "avg_loss_percent": avg_loss,
                }
        except Exception as e:
            logger.error(f"Failed to get trades statistics: {e}")
            return {}

    # ==================== Phase 4.5: AIé£é™©é¡¾é—®ç³»ç»Ÿæ¥å£ ====================

    def create_risk_analysis(self, trade_plan: Dict) -> int:
        """
        åˆ›å»ºæ–°çš„é£é™©åˆ†æè®°å½•ï¼ˆç”¨æˆ·è¾“å…¥äº¤æ˜“è®¡åˆ’ï¼‰

        Args:
            trade_plan: äº¤æ˜“è®¡åˆ’å­—å…¸ï¼ŒåŒ…å«ï¼š
                - symbol: äº¤æ˜“å¯¹
                - timeframe: æ—¶é—´æ¡†æ¶
                - direction: LONG/SHORT
                - entry_price: å…¥åœºä»·æ ¼
                - stop_loss: æ­¢æŸä»·æ ¼
                - take_profit_1: ç¬¬ä¸€ç›®æ ‡ä½
                - take_profit_2: ç¬¬äºŒç›®æ ‡ä½ï¼ˆå¯é€‰ï¼‰
                - win_probability: ç”¨æˆ·ä¼°è®¡èƒœç‡(0-1)
                - position_size_actual: ç”¨æˆ·è®¡åˆ’ä»“ä½(%)
                - user_notes: ç”¨æˆ·å¤‡æ³¨

        Returns:
            é£é™©åˆ†æè®°å½•ID
        """
        try:
            with self._get_connection() as conn:
                cursor = conn.execute(
                    """INSERT INTO trades (
                        symbol, timeframe, direction, status,
                        entry_price, stop_loss, take_profit_1, take_profit_2,
                        win_probability, position_size_actual, user_notes,
                        created_at, updated_at
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                    (
                        trade_plan.get("symbol"),
                        trade_plan.get("timeframe", "15m"),
                        trade_plan.get("direction", "LONG"),
                        "ANALYZED",
                        trade_plan.get("entry_price"),
                        trade_plan.get("stop_loss"),
                        trade_plan.get("take_profit_1"),
                        trade_plan.get("take_profit_2"),
                        trade_plan.get("win_probability", 0.5),
                        trade_plan.get("position_size_actual", 0.0),
                        trade_plan.get("user_notes", ""),
                        int(datetime.now().timestamp() * 1000),
                        int(datetime.now().timestamp() * 1000),
                    ),
                )
                analysis_id = cursor.lastrowid
                logger.info(
                    f"Risk analysis created: ID={analysis_id}, {trade_plan.get('symbol')} "
                    f"Entry={trade_plan.get('entry_price')}, SL={trade_plan.get('stop_loss')}"
                )
                return analysis_id if analysis_id else -1
        except Exception as e:
            logger.error(f"Failed to create risk analysis: {e}")
            return -1

    def update_risk_analysis_result(self, analysis_id: int, risk_result: Dict) -> bool:
        """
        æ›´æ–°AIé£é™©åˆ†æç»“æœ

        Args:
            analysis_id: é£é™©åˆ†æè®°å½•ID
            risk_result: é£é™©åˆ†æç»“æœå­—å…¸ï¼ŒåŒ…å«ï¼š
                - risk_reward_expected: é¢„æœŸç›ˆäºæ¯”
                - position_size_suggested: AIå»ºè®®ä»“ä½(%)
                - risk_amount_percent: é£é™©é‡‘é¢(%)
                - volatility_atr: ATRæ³¢åŠ¨ç‡
                - volatility_atr_15m: 15åˆ†é’ŸATR
                - volatility_atr_1h: 1å°æ—¶ATR
                - volatility_atr_1d: æ—¥çº¿ATR
                - sharpe_ratio_estimate: ä¼°è®¡å¤æ™®æ¯”ç‡
                - kelly_fraction: å‡¯åˆ©å…¬å¼æœ€ä¼˜ä»“ä½
                - kelly_fraction_adjusted: ä¿å®ˆè°ƒæ•´åçš„å‡¯åˆ©ä»“ä½
                - max_drawdown_estimate: ä¼°è®¡æœ€å¤§å›æ’¤
                - r_multiple_plan: R-multipleè®¡åˆ’(JSON)
                - stop_distance_percent: æ­¢æŸè·ç¦»(%)
                - ai_risk_analysis: AIå®Œæ•´é£é™©åˆ†ææ–‡æœ¬
                - ai_recommendation: AIå»ºè®®æ‘˜è¦
                - risk_level: é£é™©ç­‰çº§(LOW/MEDIUM/HIGH/EXTREME)

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            with self._get_connection() as conn:
                conn.execute(
                    """UPDATE trades 
                       SET risk_reward_expected = ?,
                           position_size_suggested = ?,
                           risk_amount_percent = ?,
                           volatility_atr = ?,
                           volatility_atr_15m = ?,
                           volatility_atr_1h = ?,
                           volatility_atr_1d = ?,
                           sharpe_ratio_estimate = ?,
                           kelly_fraction = ?,
                           kelly_fraction_adjusted = ?,
                           max_drawdown_estimate = ?,
                           r_multiple_plan = ?,
                           stop_distance_percent = ?,
                           ai_risk_analysis = ?,
                           ai_recommendation = ?,
                           risk_level = ?,
                           analysis_timestamp = ?,
                           updated_at = ?
                       WHERE id = ?""",
                    (
                        risk_result.get("risk_reward_expected", 0.0),
                        risk_result.get("position_size_suggested", 0.0),
                        risk_result.get("risk_amount_percent", 0.0),
                        risk_result.get("volatility_atr", 0.0),
                        risk_result.get("volatility_atr_15m", 0.0),
                        risk_result.get("volatility_atr_1h", 0.0),
                        risk_result.get("volatility_atr_1d", 0.0),
                        risk_result.get("sharpe_ratio_estimate", 0.0),
                        risk_result.get("kelly_fraction", 0.0),
                        risk_result.get("kelly_fraction_adjusted", 0.0),
                        risk_result.get("max_drawdown_estimate", 0.0),
                        json.dumps(risk_result.get("r_multiple_plan", {})),
                        risk_result.get("stop_distance_percent", 0.0),
                        risk_result.get("ai_risk_analysis", ""),
                        risk_result.get("ai_recommendation", ""),
                        risk_result.get("risk_level", "MEDIUM"),
                        int(datetime.now().timestamp() * 1000),
                        int(datetime.now().timestamp() * 1000),
                        analysis_id,
                    ),
                )
                logger.info(f"Risk analysis result updated: ID={analysis_id}")
                return True
        except Exception as e:
            logger.error(f"Failed to update risk analysis result {analysis_id}: {e}")
            return False

    def get_risk_analysis(self, analysis_id: int) -> Optional[Dict]:
        """
        è·å–æŒ‡å®šé£é™©åˆ†æè®°å½•

        Args:
            analysis_id: é£é™©åˆ†æè®°å½•ID

        Returns:
            é£é™©åˆ†æå­—å…¸æˆ–None
        """
        try:
            with self._get_connection() as conn:
                cursor = conn.execute(
                    "SELECT * FROM trades WHERE id = ?",
                    (analysis_id,),
                )
                row = cursor.fetchone()
                if row:
                    result = dict(row)
                    # è§£æJSONå­—æ®µ
                    if result.get("r_multiple_plan"):
                        try:
                            result["r_multiple_plan"] = json.loads(
                                result["r_multiple_plan"]
                            )
                        except:
                            result["r_multiple_plan"] = {}
                    return result
                return None
        except Exception as e:
            logger.error(f"Failed to get risk analysis {analysis_id}: {e}")
            return None

    def get_risk_analysis_history(
        self, symbol: str = "", status: str = "", limit: int = 100
    ) -> List[Dict]:
        """
        è·å–é£é™©åˆ†æå†å²è®°å½•

        Args:
            symbol: å¯é€‰ï¼Œç­›é€‰ç‰¹å®šäº¤æ˜“å¯¹
            status: å¯é€‰ï¼Œç­›é€‰çŠ¶æ€(ANALYZED/CLOSED/EXPIRED)
            limit: è¿”å›æ•°é‡é™åˆ¶

        Returns:
            é£é™©åˆ†æè®°å½•åˆ—è¡¨
        """
        try:
            with self._get_connection() as conn:
                query = "SELECT * FROM trades WHERE 1=1"
                params = []

                if symbol:
                    query += " AND symbol = ?"
                    params.append(symbol)
                if status:
                    query += " AND status = ?"
                    params.append(status)

                query += " ORDER BY created_at DESC LIMIT ?"
                params.append(limit)

                cursor = conn.execute(query, params)
                rows = cursor.fetchall()

                results = []
                for row in rows:
                    result = dict(row)
                    # è§£æJSONå­—æ®µ
                    if result.get("r_multiple_plan"):
                        try:
                            result["r_multiple_plan"] = json.loads(
                                result["r_multiple_plan"]
                            )
                        except:
                            result["r_multiple_plan"] = {}
                    results.append(result)

                return results
        except Exception as e:
            logger.error(f"Failed to get risk analysis history: {e}")
            return []

    def close_risk_analysis(
        self, analysis_id: int, outcome_feedback: str = "", notes: str = ""
    ) -> bool:
        """
        ç”¨æˆ·æ ‡è®°å…³é—­é£é™©åˆ†æè®°å½•ï¼ˆè®°å½•å®é™…ç»“æœåé¦ˆï¼‰

        Args:
            analysis_id: é£é™©åˆ†æè®°å½•ID
            outcome_feedback: ç”¨æˆ·åé¦ˆçš„å®é™…ç»“æœ(WIN/LOSS/å…¶ä»–)
            notes: å¤‡æ³¨

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            with self._get_connection() as conn:
                conn.execute(
                    """UPDATE trades 
                       SET status = 'CLOSED',
                           outcome_feedback = ?,
                           user_notes = CASE WHEN user_notes = '' THEN ? ELSE user_notes || '; ' || ? END,
                           updated_at = ?
                       WHERE id = ?""",
                    (
                        outcome_feedback,
                        notes,
                        notes,
                        int(datetime.now().timestamp() * 1000),
                        analysis_id,
                    ),
                )
                logger.info(
                    f"Risk analysis closed: ID={analysis_id}, outcome={outcome_feedback}"
                )
                return True
        except Exception as e:
            logger.error(f"Failed to close risk analysis {analysis_id}: {e}")
            return False

    def expire_risk_analysis(self, analysis_id: int) -> bool:
        """
        å°†é£é™©åˆ†æè®°å½•æ ‡è®°ä¸ºè¿‡æœŸ

        Args:
            analysis_id: é£é™©åˆ†æè®°å½•ID

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            with self._get_connection() as conn:
                conn.execute(
                    """UPDATE trades 
                       SET status = 'EXPIRED',
                           updated_at = ?
                       WHERE id = ?""",
                    (
                        int(datetime.now().timestamp() * 1000),
                        analysis_id,
                    ),
                )
                logger.info(f"Risk analysis expired: ID={analysis_id}")
                return True
        except Exception as e:
            logger.error(f"Failed to expire risk analysis {analysis_id}: {e}")
            return False

    # ==================== Phase 6: æ–°é—»æƒ…æŠ¥æ¨¡å—æ¥å£ ====================

    def save_news_item(self, item) -> str:
        """
        ä¿å­˜æ–°é—»æ¡ç›®

        Args:
            item: NewsItemå¯¹è±¡æˆ–å­—å…¸

        Returns:
            ä¿å­˜çš„æ¡ç›®IDï¼ˆUUIDï¼‰
        """
        try:
            # å…¼å®¹ NewsItem å¯¹è±¡å’Œå­—å…¸
            if hasattr(item, "model_dump"):
                # Pydantic å¯¹è±¡è½¬å­—å…¸
                data = item.model_dump()
            elif hasattr(item, "__dict__"):
                # æ™®é€šå¯¹è±¡
                data = item.__dict__
            elif isinstance(item, dict):
                data = item
            else:
                logger.error(f"Unknown item type: {type(item)}")
                return ""

            with self._get_connection() as conn:
                cursor = conn.execute(
                    """INSERT OR IGNORE INTO news_items (
                        id, source, source_item_id, title, url,
                        published_time_utc, ingest_time_utc,
                        content, language,
                        votes_positive, votes_negative, votes_installed,
                        domain, kind, status,
                        created_at, updated_at
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                    (
                        data.get("id"),
                        data.get("source"),
                        data.get("source_item_id"),
                        data.get("title"),
                        data.get("url"),
                        data.get("published_time_utc"),
                        data.get("ingest_time_utc"),
                        data.get("content"),
                        data.get("language"),
                        data.get("votes_positive", 0),
                        data.get("votes_negative", 0),
                        data.get("votes_installed", 0),
                        data.get("domain"),
                        data.get("kind"),
                        data.get("status", "NEW"),
                        data.get("created_at"),
                        data.get("updated_at"),
                    ),
                )
                if cursor.rowcount > 0:
                    item_id = data.get("id", "")
                    if item_id:
                        logger.debug(f"News item saved: {item_id[:8]}...")
                    return item_id
                else:
                    # å·²å­˜åœ¨ï¼Œè¿”å›å·²æœ‰ID
                    cursor = conn.execute(
                        "SELECT id FROM news_items WHERE source = ? AND source_item_id = ?",
                        (data.get("source"), data.get("source_item_id")),
                    )
                    row = cursor.fetchone()
                    return row["id"] if row and row["id"] else data.get("id", "")
        except Exception as e:
            logger.error(f"Failed to save news item: {e}")
            return ""

    def get_news_item(self, news_id: str) -> Optional[Dict]:
        """
        è·å–æ–°é—»æ¡ç›®

        Args:
            news_id: æ–°é—»æ¡ç›®ID

        Returns:
            æ–°é—»æ¡ç›®å­—å…¸æˆ–None
        """
        try:
            with self._get_connection() as conn:
                cursor = conn.execute(
                    "SELECT * FROM news_items WHERE id = ?",
                    (news_id,),
                )
                row = cursor.fetchone()
                return dict(row) if row else None
        except Exception as e:
            logger.error(f"Failed to get news item {news_id}: {e}")
            return None

    def get_pending_news_items(self, limit: int = 100) -> List[Dict]:
        """
        è·å–å¾…å¤„ç†çš„æ–°é—»æ¡ç›®

        Args:
            limit: è¿”å›æ•°é‡é™åˆ¶

        Returns:
            æ–°é—»æ¡ç›®åˆ—è¡¨
        """
        try:
            with self._get_connection() as conn:
                cursor = conn.execute(
                    """SELECT * FROM news_items
                       WHERE status = 'NEW'
                       ORDER BY published_time_utc DESC
                       LIMIT ?""",
                    (limit,),
                )
                return [dict(row) for row in cursor.fetchall()]
        except Exception as e:
            logger.error(f"Failed to get pending news items: {e}")
            return []

    def get_recent_news_items(self, limit: int = 50) -> List[Dict]:
        """
        è·å–æœ€è¿‘çš„æ–°é—»æ¡ç›®ï¼ˆç”¨äºæµæ°´çº¿å¤„ç†ï¼‰

        Args:
            limit: è¿”å›æ•°é‡é™åˆ¶

        Returns:
            æ–°é—»æ¡ç›®åˆ—è¡¨
        """
        try:
            with self._get_connection() as conn:
                cursor = conn.execute(
                    """SELECT * FROM news_items
                       ORDER BY published_time_utc DESC
                       LIMIT ?""",
                    (limit,),
                )
                return [dict(row) for row in cursor.fetchall()]
        except Exception as e:
            logger.error(f"Failed to get recent news items: {e}")
            return []

    def update_news_status(
        self, news_id: str, status: str, error: Optional[str] = None
    ) -> bool:
        """
        æ›´æ–°æ–°é—»æ¡ç›®çŠ¶æ€

        Args:
            news_id: æ–°é—»æ¡ç›®ID
            status: æ–°çŠ¶æ€
            error: é”™è¯¯ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰

        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            with self._get_connection() as conn:
                conn.execute(
                    """UPDATE news_items
                       SET status = ?, error = ?, updated_at = ?
                       WHERE id = ?""",
                    (
                        status,
                        error,
                        int(datetime.now().timestamp() * 1000),
                        news_id,
                    ),
                )
                return True
        except Exception as e:
            logger.error(f"Failed to update news status: {e}")
            return False

    def save_refined_doc(self, doc) -> str:
        """
        ä¿å­˜æçº¯æ–‡æ¡£

        Args:
            doc: RefinedDocå¯¹è±¡æˆ–å­—å…¸

        Returns:
            ä¿å­˜çš„æ–‡æ¡£IDï¼ˆUUIDï¼‰
        """
        try:
            # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœä¼ å…¥çš„æ˜¯ Pydantic å¯¹è±¡ï¼Œè½¬ä¸ºå­—å…¸
            if hasattr(doc, "model_dump"):
                data = doc.model_dump()
            elif hasattr(doc, "dict"):
                data = doc.dict()
            elif isinstance(doc, dict):
                data = doc
            else:
                logger.error(f"Unknown doc type: {type(doc)}")
                return ""

            with self._get_connection() as conn:
                cursor = conn.execute(
                    """INSERT OR IGNORE INTO refined_docs (
                        id, news_id, final_url, url_hash,
                        content_type, markdown, text_content,
                        extract_method, content_hash, simhash,
                        status, refine_time_utc, created_at
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                    (
                        data.get("id"),
                        data.get("news_id"),
                        data.get("final_url"),
                        data.get("url_hash"),
                        data.get("content_type"),
                        data.get("markdown"),
                        data.get("text_content"),
                        data.get("extract_method"),
                        data.get("content_hash"),
                        data.get("simhash"),
                        data.get("status", "COMPLETED"),
                        data.get("refine_time_utc"),
                        data.get("created_at"),
                    ),
                )
                doc_id = data.get("id", "")
                if doc_id:
                    logger.debug(f"Refined doc saved: {doc_id[:8]}...")
                return doc_id
        except Exception as e:
            logger.error(f"Failed to save refined doc: {e}")
            return ""

    def get_refined_doc_by_news_id(self, news_id: str) -> Optional[Dict]:
        """
        é€šè¿‡news_idè·å–æçº¯æ–‡æ¡£

        Args:
            news_id: æ–°é—»æ¡ç›®ID

        Returns:
            æçº¯æ–‡æ¡£å­—å…¸æˆ–None
        """
        try:
            with self._get_connection() as conn:
                cursor = conn.execute(
                    "SELECT * FROM refined_docs WHERE news_id = ? ORDER BY created_at DESC LIMIT 1",
                    (news_id,),
                )
                row = cursor.fetchone()
                return dict(row) if row else None
        except Exception as e:
            logger.error(f"Failed to get refined doc for {news_id}: {e}")
            return None

    def save_news_signal(self, signal: Dict) -> str:
        """
        ä¿å­˜æ–°é—»ä¿¡å·

        Args:
            signal: æ–°é—»ä¿¡å·å­—å…¸

        Returns:
            ä¿å­˜çš„ä¿¡å·ID
        """
        try:
            with self._get_connection() as conn:
                cursor = conn.execute(
                    """INSERT OR REPLACE INTO news_signals (
                        id, signal_id, event_type, assets, market_scope,
                        direction_hint, impact_volatility, tail_risk,
                        time_horizon, confidence, attention_score, credibility_score,
                        news_ids, evidence_urls,
                        one_line_thesis, full_analysis,
                        rank_score, created_time_utc,
                        expires_at_utc, is_active, reviewed,
                        created_at, updated_at
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)""",
                    (
                        signal.get("id"),
                        signal.get("signal_id"),
                        signal.get("event_type"),
                        json.dumps(signal.get("assets", [])),
                        signal.get("market_scope"),
                        signal.get("direction_hint"),
                        signal.get("impact_volatility", 1),
                        signal.get("tail_risk", 1),
                        signal.get("time_horizon", "hours"),
                        signal.get("confidence", 0.5),
                        signal.get("attention_score", 0.0),
                        signal.get("credibility_score", 0.5),
                        json.dumps(signal.get("news_ids", [])),
                        json.dumps(signal.get("evidence_urls", [])),
                        signal.get("one_line_thesis"),
                        signal.get("full_analysis"),
                        signal.get("rank_score", 0.0),
                        signal.get("created_time_utc"),
                        signal.get("expires_at_utc"),
                        signal.get("is_active", 1),
                        signal.get("reviewed", 0),
                        signal.get("created_at"),
                        signal.get("updated_at"),
                    ),
                )
                signal_id = signal.get("signal_id", "")
                logger.info(f"News signal saved: {signal_id}")
                return signal_id
        except Exception as e:
            logger.error(f"Failed to save news signal: {e}")
            return ""

    def get_latest_news_signals(
        self,
        window_hours: int = 6,
        topk: int = 5,
        min_rank_score: float = 0.3,
        assets: Optional[List[str]] = None,
    ) -> List[Dict]:
        """
        è·å–æœ€æ–°çš„æ–°é—»ä¿¡å·ï¼ˆç”¨äºæ³¨å…¥AI Promptï¼‰

        Args:
            window_hours: æ—¶é—´çª—å£ï¼ˆå°æ—¶ï¼‰
            topk: è¿”å›æ•°é‡ä¸Šé™
            min_rank_score: æœ€å°æ’åºåˆ†æ•°
            assets: ç­›é€‰ç‰¹å®šèµ„äº§

        Returns:
            æ–°é—»ä¿¡å·åˆ—è¡¨
        """
        try:
            cutoff = int(datetime.now().timestamp() * 1000) - window_hours * 3600 * 1000

            with self._get_connection() as conn:
                if assets:
                    # æ„å»ºLIKEæŸ¥è¯¢
                    asset_conditions = " OR ".join([f"assets LIKE ?" for _ in assets])
                    cursor = conn.execute(
                        f"""SELECT * FROM news_signals
                            WHERE created_time_utc > ?
                            AND is_active = 1
                            AND rank_score >= ?
                            AND ({asset_conditions})
                            ORDER BY rank_score DESC
                            LIMIT ?""",
                        [cutoff, min_rank_score]
                        + [f'%"{a}"%' for a in assets]
                        + [topk],
                    )
                else:
                    cursor = conn.execute(
                        """SELECT * FROM news_signals
                           WHERE created_time_utc > ?
                           AND is_active = 1
                           AND rank_score >= ?
                           ORDER BY rank_score DESC
                           LIMIT ?""",
                        (cutoff, min_rank_score, topk),
                    )

                rows = cursor.fetchall()
                signals = []
                for row in rows:
                    signal = dict(row)
                    # è§£æJSONå­—æ®µ
                    signal["assets"] = json.loads(signal["assets"])
                    signal["news_ids"] = json.loads(signal["news_ids"])
                    signal["evidence_urls"] = json.loads(signal["evidence_urls"])
                    signals.append(signal)

                return signals
        except Exception as e:
            logger.error(f"Failed to get latest news signals: {e}")
            return []

    def get_news_signals_by_assets(
        self, assets: List[str], limit: int = 50
    ) -> List[Dict]:
        """
        è·å–ç‰¹å®šèµ„äº§çš„æ–°é—»ä¿¡å·

        Args:
            assets: èµ„äº§åˆ—è¡¨
            limit: è¿”å›æ•°é‡é™åˆ¶

        Returns:
            æ–°é—»ä¿¡å·åˆ—è¡¨
        """
        try:
            with self._get_connection() as conn:
                conditions = " OR ".join([f"assets LIKE ?" for _ in assets])
                cursor = conn.execute(
                    f"""SELECT * FROM news_signals
                        WHERE ({conditions})
                        ORDER BY created_time_utc DESC
                        LIMIT ?""",
                    [f'%"{a}"%' for a in assets] + [limit],
                )

                rows = cursor.fetchall()
                signals = []
                for row in rows:
                    signal = dict(row)
                    signal["assets"] = json.loads(signal["assets"])
                    signal["news_ids"] = json.loads(signal["news_ids"])
                    signal["evidence_urls"] = json.loads(signal["evidence_urls"])
                    signals.append(signal)

                return signals
        except Exception as e:
            logger.error(f"Failed to get news signals by assets: {e}")
            return []

    def get_high_impact_signals(
        self, impact_threshold: int = 3, tail_risk_threshold: int = 2, limit: int = 20
    ) -> List[Dict]:
        """
        è·å–é«˜å½±å“ä¿¡å·ï¼ˆç”¨äºå‘Šè­¦ï¼‰

        Args:
            impact_threshold: æœ€å°æ³¢åŠ¨å½±å“é˜ˆå€¼
            tail_risk_threshold: æœ€å°å°¾éƒ¨é£é™©é˜ˆå€¼
            limit: è¿”å›æ•°é‡é™åˆ¶

        Returns:
            é«˜å½±å“ä¿¡å·åˆ—è¡¨
        """
        try:
            with self._get_connection() as conn:
                cursor = conn.execute(
                    """SELECT * FROM news_signals
                       WHERE is_active = 1
                       AND (impact_volatility >= ? OR tail_risk >= ?)
                       ORDER BY rank_score DESC
                       LIMIT ?""",
                    (impact_threshold, tail_risk_threshold, limit),
                )

                rows = cursor.fetchall()
                signals = []
                for row in rows:
                    signal = dict(row)
                    signal["assets"] = json.loads(signal["assets"])
                    signal["news_ids"] = json.loads(signal["news_ids"])
                    signal["evidence_urls"] = json.loads(signal["evidence_urls"])
                    signals.append(signal)

                return signals
        except Exception as e:
            logger.error(f"Failed to get high impact signals: {e}")
            return []

    def deactivate_expired_signals(self) -> int:
        """
        æ ‡è®°è¿‡æœŸçš„ä¿¡å·ä¸ºéæ´»è·ƒ

        Returns:
            æ›´æ–°çš„è®°å½•æ•°
        """
        try:
            now = int(datetime.now().timestamp() * 1000)
            with self._get_connection() as conn:
                cursor = conn.execute(
                    """UPDATE news_signals
                       SET is_active = 0, updated_at = ?
                       WHERE expires_at_utc IS NOT NULL
                       AND expires_at_utc < ?
                       AND is_active = 1""",
                    (now, now),
                )
                if cursor.rowcount > 0:
                    logger.info(f"Deactivated {cursor.rowcount} expired signals")
                return cursor.rowcount
        except Exception as e:
            logger.error(f"Failed to deactivate expired signals: {e}")
            return 0

    def cleanup_old_news_data(self, days: int = 30) -> Dict[str, int]:
        """
        æ¸…ç†æ—§æ–°é—»æ•°æ®

        Args:
            days: ä¿ç•™å¤©æ•°

        Returns:
            å„è¡¨åˆ é™¤æ•°é‡çš„å­—å…¸
        """
        try:
            cutoff = int((datetime.now().timestamp() - days * 86400) * 1000)

            deleted = {}

            with self._get_connection() as conn:
                # æ¸…ç†è¿‡æœŸä¿¡å·
                cursor = conn.execute(
                    "DELETE FROM news_signals WHERE created_time_utc < ?",
                    (cutoff,),
                )
                deleted["signals"] = cursor.rowcount

                # æ¸…ç†æ—§èšç±»
                cursor = conn.execute(
                    "DELETE FROM event_clusters WHERE created_at < ?",
                    (cutoff,),
                )
                deleted["clusters"] = cursor.rowcount

                # æ¸…ç†7å¤©å‰çš„refined_docs
                cutoff_refined = int((datetime.now().timestamp() - 7 * 86400) * 1000)
                cursor = conn.execute(
                    "DELETE FROM refined_docs WHERE created_at < ?",
                    (cutoff_refined,),
                )
                deleted["refined_docs"] = cursor.rowcount

                # æ¸…ç†7å¤©å‰çš„news_items
                cursor = conn.execute(
                    "DELETE FROM news_items WHERE created_at < ?",
                    (cutoff_refined,),
                )
                deleted["news_items"] = cursor.rowcount

            logger.info(f"Cleaned up news data: {deleted}")
            return deleted
        except Exception as e:
            logger.error(f"Failed to cleanup old news data: {e}")
            return {}
